# Aptix Agent Session Architecture & State Model

## 1. Overview
This document defines the state model, storage model, policies, and request/response flow for Aptix Agent Sessions. It merges all finalized agreements from our previous discussions.

## 2. Core Concepts

### 2.1 AgentSession (top‑level conversation)
An AgentSession is the long‑lived thread of work (like the left‑panel threads in ChatGPT).  
It:
- Has a stable **SessionId** (GUID generated by our system).
- Contains many **Responses**.
- Tracks expiration of OpenAI `previous_response_id`.
- Stores metadata and summaries to prevent loss of continuity.

### 2.2 Responses (per-round trip)
Each call to the OpenAI Responses API produces:
- A **platform response id** → used as `previous_response_id`.
- Our **internal ResponseId**.
- A timestamp.
- The **full request payload** (stored).
- The **full response payload** (stored).
- A list of **retrieved vector chunk IDs**.
- A list of **active files** transmitted to the LLM.

Responses are immutable records.

### 2.3 Relationship Diagram

```
AgentSession
 ├── SessionId (ours)
 ├── Name
 ├── CreatedUtc
 ├── ExpiresUtc
 └── Responses[]
        ├── InternalResponseId (ours)
        ├── OpenAIResponseId (platform)
        ├── RetrievedChunkIds[]
        ├── ActiveFiles[]
        ├── RequestPayload
        ├── ResponsePayload
        └── TimestampUtc
```

---

## 3. Vector DB & RAG Retrieval Policy

### 3.1 First Request
On the first request:
- The human may upload large specs/schemas.
- These are embedded or chunked (depending on source).
- We call Qdrant with:
  - **AgentContext** → which vector DB and which LLM environment
  - **ConversationContext** → system prompt, model, temperature
  - **Workspace filter (optional)** → e.g., `workspace:NuvOS.DesignPlayground`

We store:
- All retrieved chunk IDs.
- The exact text of all snippets passed to the LLM.
- Summaries if needed.

### 3.2 Subsequent Requests
When doing a follow‑up:
- We send **previous_response_id** only.
- We do **NOT** repeat initial files.
- BUT we still perform RAG retrieval again, because:
  - The new question may need new context.
  - The previous snippets may not be enough.

We then:
- Compare retrieved chunk IDs against the prior response.
- Only send **new** snippets when needed (for optimization).
- Always include active files (local edits).

---

## 4. WorkspaceId (Request‑Only, NOT stored in vector DB)

### 4.1 Why WorkspaceId exists
WorkspaceId identifies the **current working copy** of the repo the developer is editing.

Examples:
- `NuvOS.MainRepo.KevinLaptop1`
- `GlaBackend.FredDesktop1`

It **does not** get written into the vector DB metadata.

### 4.2 Purpose
WorkspaceId is used for:
- Path filtering during RAG retrieval (e.g. only ui/primitives files).
- Session scoping (each dev has their own workspace).
- Understanding which local files were active in prior responses.
- Resolving conflicts between server-indexed and local-edited versions.

### 4.3 WorkspaceId does **not** imply local indexing
You currently index **on commit in CI**.  
WorkspaceId comes from the **human request**, not from Qdrant metadata.

---

## 5. Active File Policy

### 5.1 When a file is considered active
A file is “active” when:
- It has local modifications (via Git dirty check), or
- The extension reports it as open/edited, or
- The human explicitly provides it.

### 5.2 Transmission Policy
We **always send the entire active file** to the LLM (not just diffs).

Rationale:
- Ensures deterministic patching.
- Prevents drift from uncommitted local state.
- V1 reliability > micro‑optimization.

### 5.3 Skip large files
If a file > 100 KB:
- We skip sending it.
- We include a `skipped_files[]` list in our stored request metadata.
- This is included in troubleshooting output.

---

## 6. Determining When to Re‑Send an Active File

### 6.1 Hashing
For each active file we store:
- FilePath
- SHA‑256 of contents

On the next request:
- Recompute hash.
- If changed → resend file.
- If unchanged → do not resend (RAG + previous_response_id sufficient).

### 6.2 Why SHA‑256?
- Stable.
- Language‑agnostic.
- Prevents noise from whitespace-only changes.

---

## 7. Vector Chunk Tracking

### 7.1 Why track chunk IDs?
Because:
- If a new request retrieves different chunks, we can see **what changed**.
- Allows session summaries and troubleshooting.
- Helps with model grounding.

### 7.2 What we store
Per Response:
- List of Qdrant `point_ids`.
- Also store their path/start/end for debugging.

### 7.3 What we send next time
We bundle only:
- Active files
- New snippets from new RAG retrieval

---

## 8. How the Responses API Fits In

### 8.1 State model
The Responses API keeps state **per previous_response_id**, but this state:
- Is temporary (~30 days)
- Is not guaranteed to persist
- Is not your full memory (you must store everything yourself)

### 8.2 What we store
Because OpenAI does NOT store your full session:
- We store every Response locally
- We rehydrate context on every follow‑up request

### 8.3 What goes to OpenAI
Each follow-up request:
- Sends `previous_response_id`
- Plus **only the deltas**:
  - New RAG snippets
  - Updated active files
  - The new question

---

## 9. Expiration Policy

### 9.1 How expiration works
OpenAI’s response state expires:
- Roughly **30 days after creation**
- NOT exactly, not guaranteed

Thus:
- We store `OpenAIResponseId` + `TimestampUtc`
- Compute `ExpiresUtc = TimestampUtc + 30 days`
- If expired:
  - We start a **new** Responses chain
  - But we preload everything from our durable storage

This gives:
- Infinite session life on your end
- Zero dependency on OpenAI persistence

---

## 10. Durable Storage Model

### 10.1 Two Collections
1. **AgentSessions**
2. **AgentSessionResponses**

### 10.2 Stored Data
We store fields such as:
- Entire request payload
- Entire response payload
- Chunk IDs used
- Active files with hashes
- Skipped files
- Error messages
- Original question
- WorkspaceId
- Repo + Language + RagScope

---

## 11. Combined Flow Summary

### 11.1 Initial request (no previous_response_id)
1. Human sends query + files
2. RAG retrieves chunks
3. Active files sent
4. Request sent to Responses API
5. We store:
   - Request
   - Response
   - Chunks
   - File hashes

### 11.2 Follow‑up request
1. Human provides new Instruction
2. We:
   - Look up last Response
   - Include `previous_response_id`
   - Recompute active file hashes
   - Fetch new RAG snippets
3. Send minimal payload:
   - New local files or modified ones
   - New snippets
4. Store the result

### 11.3 Expired chain
- Detect expiration
- Create new chain
- Preload previous session’s files + snippets + summaries

---

## 12. Future Extensions
- Temperature normalization
- Model migration procedures
- Cross‑workspace comparative reasoning
- Structured session summaries
- Request slimming heuristics
- Caching of RAG results per-session
